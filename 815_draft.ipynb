{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wavenet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Sequence, Union, Optional\n",
    "from wavenet590.modules.attention import (\n",
    "    SelfAttention,\n",
    "    PersonalizedAttention,\n",
    "    HawkesAttention,\n",
    ")\n",
    "from wavenet590.modules.embed import PositionalEmbedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewHawkesAttention(nn.Module):\n",
    "    \"\"\"Hawkes process for attending to contexts with query\"\"\"\n",
    "\n",
    "    def __init__(self, device, dimensions, attention_type=\"general\"):\n",
    "        super(NewHawkesAttention, self).__init__()\n",
    "        self.device = device\n",
    "        if attention_type not in [\"dot\", \"general\"]:\n",
    "            raise ValueError(\"Invalid attention type selected.\")\n",
    "\n",
    "        self.attention_type = attention_type\n",
    "        if self.attention_type == \"general\":\n",
    "            self.linear_in = nn.Linear(dimensions, dimensions, bias=False)\n",
    "\n",
    "        self.linear_out = nn.Linear(dimensions * 2, dimensions, bias=False)\n",
    "        self.ae = nn.Parameter(torch.FloatTensor([0.25]).to(device), requires_grad=True)\n",
    "        self.ab = nn.Parameter(torch.FloatTensor([0.25]).to(device), requires_grad=True)\n",
    "\n",
    "    def forward(self, query, context):\n",
    "        batch_size, dimensions = query.size()\n",
    "        seq_len = context.size(1)\n",
    "\n",
    "        if self.attention_type == \"general\":\n",
    "            query = self.linear_in(query)\n",
    "\n",
    "        att_scores = torch.bmm(query.unsqueeze(1), context.transpose(1, 2).contiguous())\n",
    "        att_scores = F.softmax(att_scores, dim=-1)\n",
    "        mix = att_scores * (context.permute(0, 2, 1))\n",
    "\n",
    "        # --- time dacay impact ---\n",
    "        delta_t = (\n",
    "            torch.flip(torch.arange(0, seq_len), [0])\n",
    "            .type(torch.float32)\n",
    "            .to(self.device)\n",
    "        )\n",
    "        delta_t = delta_t.repeat(batch_size, 1).reshape(batch_size, 1, seq_len)\n",
    "\n",
    "        bt = torch.exp(-1 * self.ab * delta_t)\n",
    "        term_2 = F.relu(self.ae * mix * bt)\n",
    "        mix = torch.sum(term_2 + mix, -1)\n",
    "        combined = torch.cat((mix, query), dim=-1)\n",
    "        output = self.linear_out(combined)\n",
    "        output = torch.tanh(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalModule(nn.Module):\n",
    "    \"\"\"时序模块，将时序数据处理成特征\n",
    "    基本是一个类似WaveNet的结构，先进行Position Embedding，然后经过多层的dilate conv，并应用Hawkes Attention\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        device: torch.device,\n",
    "        in_dim: int,\n",
    "        filter_channels: int = 128,\n",
    "        kernel_size: int = 3,\n",
    "        dilations: Sequence[int] = (1, 2, 3, 4),\n",
    "        dropout: float = 0.3,\n",
    "        positional_embedding_d: int = 128,\n",
    "        positional_embedding_max_len: int = 100,\n",
    "    ):\n",
    "        super(TemporalModule, self).__init__()\n",
    "        self.dilations = dilations\n",
    "        self.filter_convs = nn.ModuleList()\n",
    "        self.gate_convs = nn.ModuleList()\n",
    "        self.norm = nn.ModuleList()\n",
    "        self.hawks_att = nn.ModuleList()\n",
    "        self.device = device\n",
    "        self.start_conv = nn.Conv1d(\n",
    "            in_channels=in_dim, out_channels=filter_channels, kernel_size=1\n",
    "        )\n",
    "        self.self_attention = SelfAttention(\n",
    "            filter_channels, attention_type=\"dot\", norm=True, drop=dropout\n",
    "        )\n",
    "\n",
    "        self.position_embedding = PositionalEmbedding(\n",
    "            d_model=positional_embedding_d, max_len=positional_embedding_max_len\n",
    "        )\n",
    "\n",
    "        for i in range(len(self.dilations)):\n",
    "            self.filter_convs.append(\n",
    "                nn.Conv1d(\n",
    "                    in_channels=filter_channels,\n",
    "                    out_channels=filter_channels,\n",
    "                    kernel_size=kernel_size,\n",
    "                    dilation=self.dilations[i],\n",
    "                )\n",
    "            )\n",
    "\n",
    "            self.gate_convs.append(\n",
    "                nn.Conv1d(\n",
    "                    in_channels=filter_channels,\n",
    "                    out_channels=filter_channels,\n",
    "                    kernel_size=kernel_size,\n",
    "                    dilation=self.dilations[i],\n",
    "                )\n",
    "            )\n",
    "\n",
    "            self.norm.append(nn.BatchNorm1d(filter_channels))\n",
    "            self.hawks_att.append(HawkesAttention(device, filter_channels))\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        batch_size, num_nodes, num_days, num_features = input.shape\n",
    "        input = input.reshape(-1, num_days, num_features)\n",
    "        pe = self.position_embedding(input)\n",
    "        input = input.permute(0, 2, 1)\n",
    "        x = self.start_conv(input)\n",
    "\n",
    "        # --- self attention ---\n",
    "        x = x.permute(0, 2, 1) + pe\n",
    "        x = x + self.self_attention(x, x, x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        stack_conv_out = []\n",
    "\n",
    "        for i in range(len(self.dilations)):\n",
    "            residual = x\n",
    "            filter = self.filter_convs[i](residual)\n",
    "            # filter = torch.tanh(filter)\n",
    "            gate = torch.sigmoid(self.gate_convs[i](residual))\n",
    "            x = filter * gate\n",
    "\n",
    "            x = x + residual[:, :, -x.size(2) :]\n",
    "            # x_t = x.view(B, N, x.shape[1], x.shape[2]).permute(0, 2, 1, 3)\n",
    "            x = self.norm[i](x)  # .permute(0, 2, 1, 3).reshape(x.shape)\n",
    "\n",
    "            # new content\n",
    "            temp_x = x.permute(0, 2, 1)\n",
    "            temp_x_past = torch.zeros(temp_x.shape, device=self.device)\n",
    "            temp_x_past[:, 1:, :] = temp_x[:, :-1, :]\n",
    "            temp_x_past[:, 0, :] = temp_x[:, 0, :]\n",
    "\n",
    "            delta_x = temp_x - temp_x_past\n",
    "\n",
    "            new_x = torch.cat((temp_x, delta_x), -1)\n",
    "            permute_new_x = new_x.permute(0, 2, 1)\n",
    "\n",
    "            # time-wise attention to readout this layer's feature sequence\n",
    "            x_out = self.hawks_att[i](permute_new_x[:, :, -1], new_x)\n",
    "            stack_conv_out.append(x_out)\n",
    "\n",
    "        stack_conv_out = torch.stack(stack_conv_out, dim=1)\n",
    "        # stack_conv_out = stack_conv_out.reshape(\n",
    "        #     batch_size, num_nodes, stack_conv_out.shape[1], stack_conv_out.shape[2]\n",
    "        # )\n",
    "\n",
    "        return stack_conv_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.models.transformer_layer import (\n",
    "    EncoderLayer,\n",
    "    DecoderLayer,\n",
    "    Encoder,\n",
    "    Decoder,\n",
    ")\n",
    "from transformer.models.attn import FullAttention, AttentionLayer\n",
    "from transformer.models.embed import DataEmbedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FundTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        c_in,\n",
    "        device=\"cpu\",\n",
    "        d_model=128,\n",
    "        n_heads=4,\n",
    "        e_layers=2,\n",
    "        d_ff=256,\n",
    "        dropout=0.0,\n",
    "        activation=\"gelu\",\n",
    "        petype=0,\n",
    "        output_attention=False,\n",
    "    ):\n",
    "        super(FundTransformer, self).__init__()\n",
    "\n",
    "        self.fund_embedding = DataEmbedding(c_in, d_model, dropout, petype)\n",
    "        self.fund_encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(\n",
    "                            False,\n",
    "                            attention_dropout=dropout,\n",
    "                            output_attention=output_attention,\n",
    "                        ),\n",
    "                        d_model,\n",
    "                        n_heads,\n",
    "                    ),\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    n_heads,\n",
    "                    dropout=dropout,\n",
    "                    activation=activation,\n",
    "                )\n",
    "                for l in range(e_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(d_model),\n",
    "        )\n",
    "        self.hawks_attn = NewHawkesAttention(device, dimensions=d_model)\n",
    "\n",
    "    def forward(self, fund_in, enc_self_mask=None):\n",
    "        # shape_in: (bs, N, T, C)\n",
    "        bs, n_stock, n_time, c = fund_in.shape\n",
    "        fund_in = fund_in.view((-1, n_time, c))\n",
    "        # shape_out: (bs, N, 1, C)\n",
    "        fund_enc_in = self.fund_embedding(fund_in)\n",
    "        fund_enc_out, _ = self.fund_encoder(fund_enc_in, attn_mask=enc_self_mask)\n",
    "\n",
    "        fund_out = self.hawks_attn(fund_enc_out[:, -1, :], fund_enc_out)\n",
    "        fund_out = fund_out.view((bs * n_stock, 1, -1))\n",
    "        return fund_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanA(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        price_c_in,\n",
    "        fund_c_in,\n",
    "        c_out=1,\n",
    "        device=\"cpu\",\n",
    "        d_model=128,\n",
    "        n_heads=2,\n",
    "        enc_layer=2,\n",
    "        dec_layer=1,\n",
    "        d_ff=256,\n",
    "        dropout=0.3,\n",
    "        activation=\"gelu\",\n",
    "        petype=0,\n",
    "        num_nodes=590,\n",
    "        stockid=30,\n",
    "        type_att_channels=16,\n",
    "    ):\n",
    "        super(PlanA, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.price_wavenet = TemporalModule(\n",
    "            device,\n",
    "            in_dim=price_c_in,\n",
    "            filter_channels=d_model,\n",
    "            positional_embedding_d=d_model,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "        self.fund_encoder = FundTransformer(\n",
    "            fund_c_in,\n",
    "            d_model=d_model,\n",
    "            n_heads=n_heads,\n",
    "            e_layers=enc_layer,\n",
    "            d_ff=d_ff,\n",
    "            dropout=dropout,\n",
    "            activation=\"gelu\",\n",
    "            petype=0,\n",
    "        )\n",
    "\n",
    "        self.hawks_attn = NewHawkesAttention(device, dimensions=d_model)\n",
    "\n",
    "        self.stock_id_embedding = nn.Parameter(\n",
    "            torch.randn(num_nodes, stockid, device=device), requires_grad=True\n",
    "        )\n",
    "        self.personalized_attn = PersonalizedAttention(\n",
    "            id_dim=stockid, query_dim=type_att_channels, fea_dim=d_model\n",
    "        )\n",
    "\n",
    "        self.dec_embedding = DataEmbedding(price_c_in, d_model, dropout, petype)\n",
    "\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(\n",
    "                            True, attention_dropout=dropout, output_attention=False\n",
    "                        ),\n",
    "                        d_model,\n",
    "                        n_heads,\n",
    "                    ),\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(\n",
    "                            False, attention_dropout=dropout, output_attention=False\n",
    "                        ),\n",
    "                        d_model,\n",
    "                        n_heads,\n",
    "                    ),\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    n_heads,\n",
    "                    dropout=dropout,\n",
    "                    activation=activation,\n",
    "                )\n",
    "                for l in range(dec_layer)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(d_model),\n",
    "        )\n",
    "\n",
    "        self.projection_decoder = nn.Linear(d_model, c_out, bias=True)\n",
    "\n",
    "    def forward(self, price_in, fund_in):\n",
    "        bs = price_in.shape[0]\n",
    "        stock_n = price_in.shape[1]\n",
    "\n",
    "        price_wave_out = self.price_wavenet(price_in)\n",
    "\n",
    "        fund_trans_out = self.fund_encoder(fund_in)\n",
    "        fund_hawks_out = self.hawks_attn(\n",
    "            fund_trans_out[:, -1, :], fund_trans_out\n",
    "        ).unsqueeze(1)\n",
    "\n",
    "        concat_feat = torch.cat((price_wave_out, fund_hawks_out), dim=1).view(\n",
    "            (bs, stock_n, -1, self.d_model)\n",
    "        )\n",
    "\n",
    "        attn_out_once_list = []\n",
    "        for concat_feat_once in concat_feat:\n",
    "            attn_out_once = self.personalized_attn(\n",
    "                self.stock_id_embedding, concat_feat_once\n",
    "            )\n",
    "            attn_out_once_list.append(attn_out_once)\n",
    "        attn_out = torch.stack(attn_out_once_list).view((-1, 1, self.d_model))\n",
    "\n",
    "        dec_in = self.dec_embedding(\n",
    "            price_in[:, :, -1, :].view((-1, 1, price_in.shape[-1]))\n",
    "        )\n",
    "        print(dec_in.shape)\n",
    "        print(attn_out.shape)\n",
    "        dec_out = self.decoder(dec_in, attn_out)\n",
    "\n",
    "        proj_out = self.projection_decoder(dec_out).view((bs, stock_n, 1))\n",
    "\n",
    "        return proj_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn((16, 10, 60, 9))\n",
    "b = torch.randn((16, 10, 4, 5))\n",
    "\n",
    "p = PlanA(price_c_in=9, fund_c_in=5, device=\"cpu\", num_nodes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([160, 1, 128])\n",
      "torch.Size([160, 1, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 10, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p(a, b).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "deff6e117060b4680ad0a91c2cc9b11e790502a6f792302898866baebf8767a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
